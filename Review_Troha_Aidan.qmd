---
title: Project Review Template 
author: AIDAN TROHA
date: "`r file.mtime(knitr::current_input())`"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
---

# Overview

Title of project:

Name of project author(s): Jacob Matta

Name of project reviewer: Aidan Troha


## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments

I like the scope of your project here. I am interested to know if dealing with a smaller geographic location made finding data to use harder or easier to obtain.

### Summary assessment (PICK ONE, DELETE THE OTHERS)
* strong contextualization and motivation


## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

As with the introduction, the scope of your questioning is clearly defined. Are there any other covariates you looked into that you did not address in this section?

### Summary assessment
* question/hypotheses fully clear


## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments

Adding a link to info about the data source is a great way of providing necessary info without taking away from your analyses. I like this!

### Summary assessment
* source and overall structure of data well explained


## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

The analyses employed make rational sense, and the steps seem easy enough to follow. I counldn't wrap my head around the structure of the README.md files, but that is just a style preference from me.

### Summary assessment
* some weaknesses in wrangling and exploratory component



## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments

From what I can tell, the analyses are done appropriately and correctly. Good implementation of machine learning methods.

### Summary assessment
* strong and reasonable analysis

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments

There are plenty of figures to comment on. As a semantic argument, I wonder if you could find a way to collapse some of these figures into a more concise, paneled figure.

### Summary assessment
* results are very well presented


## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments

As of review: no discussion or conclusion statements.

### Summary assessment
* major parts of discussion missing or wrong 


## Further comments

Great work so far! 

# Overall project content evaluation
Evaluate overall features of the project  by filling in the sections below.


## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments

As the default structure, this is sufficient. Personally, I like a more intuitive structure wherein the steps of the analyses follow the order of the manuscript.

### Summary assessment
* mostly clear, but some confusing parts (e.g. useless files, things in the wrong folders)


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

As per the previous response, it makes it difficult to track down where each file is located.

### Summary assessment
* decently documented with some gaps



## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention? Are you able to re-run the whole analysis without having to do manual interventions/edits?

### Feedback and Comments

In the same vein as the previous, it can be difficult to fix an issue if you can't find the right file. In that, I mean it helps to have clearer readme files and intuitive file structure.


### Summary assessment
* small parts not reproducible or required manual intervention 


## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

It is clear that you have put a lot of thought into this project as at each step your methods well argued and appropriate.

### Summary assessment
* strong level of thorougness


## Further comments

Great job! I can tell that you have put a lot of work into this project!




